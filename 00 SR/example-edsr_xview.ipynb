{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733465713.288020  244700 gpu_device.cc:2022] Created device /device:GPU:0 with 11539 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465713.289076  244700 gpu_device.cc:2022] Created device /device:GPU:1 with 11539 MB memory:  -> device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465713.290010  244700 gpu_device.cc:2022] Created device /device:GPU:2 with 11539 MB memory:  -> device: 2, name: NVIDIA TITAN Xp, pci bus id: 0000:08:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465713.293358  244700 gpu_device.cc:2022] Created device /device:GPU:3 with 11539 MB memory:  -> device: 3, name: NVIDIA TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465713.294241  244700 gpu_device.cc:2022] Created device /device:GPU:4 with 11539 MB memory:  -> device: 4, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465713.295076  244700 gpu_device.cc:2022] Created device /device:GPU:5 with 11539 MB memory:  -> device: 5, name: NVIDIA TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465713.295852  244700 gpu_device.cc:2022] Created device /device:GPU:6 with 11539 MB memory:  -> device: 6, name: NVIDIA TITAN Xp, pci bus id: 0000:87:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465713.296627  244700 gpu_device.cc:2022] Created device /device:GPU:7 with 11539 MB memory:  -> device: 7, name: NVIDIA TITAN Xp, pci bus id: 0000:88:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14632022366647392205\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 12100173824\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 1\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 2\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 3\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 2163808062518254773\n",
       " physical_device_desc: \"device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:04:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 416903419,\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 12100173824\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 2\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 3\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 14612373335445762319\n",
       " physical_device_desc: \"device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 2144165316,\n",
       " name: \"/device:GPU:2\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 12100173824\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 1\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 3\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 467753276140719172\n",
       " physical_device_desc: \"device: 2, name: NVIDIA TITAN Xp, pci bus id: 0000:08:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 1651660799,\n",
       " name: \"/device:GPU:3\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 12100173824\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 1\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 2\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 4883426055707767164\n",
       " physical_device_desc: \"device: 3, name: NVIDIA TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 878896533,\n",
       " name: \"/device:GPU:4\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 12100173824\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 5\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 6\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 7\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 8079968579071905486\n",
       " physical_device_desc: \"device: 4, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 615190153,\n",
       " name: \"/device:GPU:5\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 12100173824\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 4\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 6\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 7\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 9469720481880949476\n",
       " physical_device_desc: \"device: 5, name: NVIDIA TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 1769886423,\n",
       " name: \"/device:GPU:6\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 12100173824\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 4\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 5\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 7\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 13215799034347408898\n",
       " physical_device_desc: \"device: 6, name: NVIDIA TITAN Xp, pci bus id: 0000:87:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 893286608,\n",
       " name: \"/device:GPU:7\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 12100173824\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 4\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 5\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 6\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 2356196853462351333\n",
       " physical_device_desc: \"device: 7, name: NVIDIA TITAN Xp, pci bus id: 0000:88:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 2099794689]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow device 확인\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 06:15:03.660790: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733465703.681774  244700 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733465703.688272  244700 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-06 06:15:03.710060: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import DIV2K, xView\n",
    "from model.edsr import edsr\n",
    "from train import EdsrTrainer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of residual blocks\n",
    "depth = 16\n",
    "\n",
    "# Super-resolution factor\n",
    "scale = 4\n",
    "\n",
    "# Downgrade operator\n",
    "downgrade = 'bicubic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of model weights (needed for demo)\n",
    "weights_dir = f'weights/xview/edsr-{depth}-x{scale}'\n",
    "weights_file = os.path.join(weights_dir, 'weights.h5')\n",
    "\n",
    "os.makedirs(weights_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "You don't need to download the DIV2K dataset as the required parts are automatically downloaded by the `DIV2K` class. By default, DIV2K images are stored in folder `.div2k` in the project's root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xview_train = xView(scale=scale, subset='train', downgrade=downgrade)\n",
    "xview_valid = xView(scale=scale, subset='valid', downgrade=downgrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching decoded images in .xView/caches/xView_train_LR_bicubic_X4.cache ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 07:23:18.063836: W tensorflow/core/kernels/data/cache_dataset_ops.cc:332] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached decoded images in .xView/caches/xView_train_LR_bicubic_X4.cache.\n",
      "Caching decoded images in .xView/caches/xView_train_HR.cache ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 07:23:50.235303: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-06 07:23:50.236683: W tensorflow/core/kernels/data/cache_dataset_ops.cc:332] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached decoded images in .xView/caches/xView_train_HR.cache.\n"
     ]
    }
   ],
   "source": [
    "train_ds = xview_train.dataset(batch_size=16, random_transform=True)\n",
    "valid_ds = xview_valid.dataset(batch_size=1, random_transform=True, repeat_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Pre-trained models\n",
    "\n",
    "If you want to skip training and directly run the demo below, download [weights-edsr-16-x4.tar.gz](https://martin-krasser.de/sisr/weights-edsr-16-x4.tar.gz) and extract the archive in the project's root directory. This will create a `weights/edsr-16-x4` directory containing the weights of the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = EdsrTrainer(model=edsr(scale=scale, num_res_blocks=depth), \n",
    "                      checkpoint_dir=f'.ckpt/xview/edsr-{depth}-x{scale}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train EDSR model for 300,000 steps and evaluate model\n",
    "# every 1000 steps on the first 10 images of the DIV2K\n",
    "# validation set. Save a checkpoint only if evaluation\n",
    "# PSNR has improved.\n",
    "trainer.train(train_ds,\n",
    "              valid_ds.take(10),\n",
    "              steps=300000, \n",
    "              evaluate_every=10, \n",
    "              save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore from checkpoint with highest PSNR\n",
    "trainer.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on full validation set\n",
    "psnrv = trainer.evaluate(valid_ds)\n",
    "print(f'PSNR = {psnrv.numpy():3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights to separate location (needed for demo)\n",
    "trainer.model.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIV2K weights와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'depth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m weights_dir2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights/edsr-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-x\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m weights_file2 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(weights_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'depth' is not defined"
     ]
    }
   ],
   "source": [
    "weights_dir2 = f'weights/edsr-{depth}-x{scale}'\n",
    "weights_file2 = os.path.join(weights_dir, 'weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_DIV2K = EdsrTrainer(model=edsr(scale=scale, num_res_blocks=depth), \n",
    "                      checkpoint_dir=f'.ckpt/edsr-{depth}-x{scale}')\n",
    "trainer_DIV2K.model.load_weights(weights_file2)\n",
    "psnr = trainer_DIV2K.evaluate(valid_ds)\n",
    "print(f'PSNR = {psnrv.numpy():3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733465738.867696  244700 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11539 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465738.868161  244700 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 11539 MB memory:  -> device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465738.868581  244700 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 11539 MB memory:  -> device: 2, name: NVIDIA TITAN Xp, pci bus id: 0000:08:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465738.868984  244700 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 11539 MB memory:  -> device: 3, name: NVIDIA TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465738.869384  244700 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 11539 MB memory:  -> device: 4, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465738.869810  244700 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 11539 MB memory:  -> device: 5, name: NVIDIA TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465738.870222  244700 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 11539 MB memory:  -> device: 6, name: NVIDIA TITAN Xp, pci bus id: 0000:87:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465738.870634  244700 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 11539 MB memory:  -> device: 7, name: NVIDIA TITAN Xp, pci bus id: 0000:88:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n",
    "\n",
    "with strategy.scope():\n",
    "    model = edsr(scale=4, num_res_blocks=16)\n",
    "    model2 = edsr(scale=4, num_res_blocks=16)\n",
    "    model.load_weights('weights/xview/edsr-16-x4-/weights.h5')\n",
    "    model2.load_weights('weights/edsr-16-x4/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import resolve_single\n",
    "from utils import load_image, plot_sample\n",
    "import tensorflow as tf\n",
    "\n",
    "def resolve_and_plot(lr_image_path):\n",
    "    lr = load_image(lr_image_path)\n",
    "    sr = resolve_single(model, lr)\n",
    "    plot_sample(lr, sr)\n",
    "\n",
    "def resolve_and_plot2(lr_image_path):\n",
    "    lr = load_image(lr_image_path)\n",
    "    sr = resolve_single(model2, lr)\n",
    "    plot_sample(lr, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following GPU devices are available: /device:GPU:0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733465658.143986  242848 gpu_device.cc:2022] Created device /device:GPU:0 with 11539 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.144600  242848 gpu_device.cc:2022] Created device /device:GPU:1 with 11539 MB memory:  -> device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.145143  242848 gpu_device.cc:2022] Created device /device:GPU:2 with 11539 MB memory:  -> device: 2, name: NVIDIA TITAN Xp, pci bus id: 0000:08:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.145681  242848 gpu_device.cc:2022] Created device /device:GPU:3 with 11539 MB memory:  -> device: 3, name: NVIDIA TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.146246  242848 gpu_device.cc:2022] Created device /device:GPU:4 with 11539 MB memory:  -> device: 4, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.146781  242848 gpu_device.cc:2022] Created device /device:GPU:5 with 11539 MB memory:  -> device: 5, name: NVIDIA TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.147322  242848 gpu_device.cc:2022] Created device /device:GPU:6 with 11539 MB memory:  -> device: 6, name: NVIDIA TITAN Xp, pci bus id: 0000:87:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.147875  242848 gpu_device.cc:2022] Created device /device:GPU:7 with 11539 MB memory:  -> device: 7, name: NVIDIA TITAN Xp, pci bus id: 0000:88:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.165008  242848 gpu_device.cc:2022] Created device /device:GPU:0 with 11539 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.165557  242848 gpu_device.cc:2022] Created device /device:GPU:1 with 11539 MB memory:  -> device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.166116  242848 gpu_device.cc:2022] Created device /device:GPU:2 with 11539 MB memory:  -> device: 2, name: NVIDIA TITAN Xp, pci bus id: 0000:08:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.166651  242848 gpu_device.cc:2022] Created device /device:GPU:3 with 11539 MB memory:  -> device: 3, name: NVIDIA TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.167182  242848 gpu_device.cc:2022] Created device /device:GPU:4 with 11539 MB memory:  -> device: 4, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.167713  242848 gpu_device.cc:2022] Created device /device:GPU:5 with 11539 MB memory:  -> device: 5, name: NVIDIA TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.168243  242848 gpu_device.cc:2022] Created device /device:GPU:6 with 11539 MB memory:  -> device: 6, name: NVIDIA TITAN Xp, pci bus id: 0000:87:00.0, compute capability: 6.1\n",
      "I0000 00:00:1733465658.168787  242848 gpu_device.cc:2022] Created device /device:GPU:7 with 11539 MB memory:  -> device: 7, name: NVIDIA TITAN Xp, pci bus id: 0000:88:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())\n",
    "    print(1)\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(1)\n",
    "    tf.config.set_visible_devices(gpus, 'GPU')\n",
    "    print(1)\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: /physical_device:GPU:0, Memory Info: {'current': 5628096256, 'peak': 11229229056}\n",
      "GPU: /physical_device:GPU:1, Memory Info: {'current': 12453888, 'peak': 13043712}\n",
      "GPU: /physical_device:GPU:2, Memory Info: {'current': 12453888, 'peak': 13043712}\n",
      "GPU: /physical_device:GPU:3, Memory Info: {'current': 12453888, 'peak': 13043712}\n",
      "GPU: /physical_device:GPU:4, Memory Info: {'current': 12453888, 'peak': 13043712}\n",
      "GPU: /physical_device:GPU:5, Memory Info: {'current': 12453888, 'peak': 13043712}\n",
      "GPU: /physical_device:GPU:6, Memory Info: {'current': 12453888, 'peak': 13043712}\n",
      "GPU: /physical_device:GPU:7, Memory Info: {'current': 12453888, 'peak': 13043712}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        details = tf.config.experimental.get_memory_info(gpu.name[17:])\n",
    "        print(f\"GPU: {gpu.name}, Memory Info: {details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 06:17:59.727998: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB (rounded to 2743541760)requested by op Conv2D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-12-06 06:17:59.728080: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1053] BFCAllocator dump for GPU_0_bfc\n",
      "2024-12-06 06:17:59.728096: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (256): \tTotal Chunks: 83, Chunks in use: 82. 20.8KiB allocated for chunks. 20.5KiB in use in bin. 17.1KiB client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728105: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728113: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (1024): \tTotal Chunks: 5, Chunks in use: 5. 5.5KiB allocated for chunks. 5.5KiB in use in bin. 5.0KiB client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728119: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728127: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (4096): \tTotal Chunks: 5, Chunks in use: 4. 33.8KiB allocated for chunks. 27.0KiB in use in bin. 27.0KiB client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728133: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728138: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728144: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728150: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728156: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (131072): \tTotal Chunks: 64, Chunks in use: 64. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728164: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (262144): \tTotal Chunks: 2, Chunks in use: 2. 545.2KiB allocated for chunks. 545.2KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728170: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (524288): \tTotal Chunks: 5, Chunks in use: 4. 2.95MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728176: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728182: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728187: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728193: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728200: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 30.66MiB allocated for chunks. 30.66MiB in use in bin. 30.66MiB client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728206: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728213: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (67108864): \tTotal Chunks: 3, Chunks in use: 2. 367.94MiB allocated for chunks. 245.29MiB in use in bin. 245.29MiB client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728222: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728229: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1060] Bin (268435456): \tTotal Chunks: 5, Chunks in use: 4. 10.87GiB allocated for chunks. 10.34GiB in use in bin. 10.22GiB client-requested in use in bin.\n",
      "2024-12-06 06:17:59.728236: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1076] Bin for 2.55GiB was 256.00MiB, Chunk State: \n",
      "2024-12-06 06:17:59.728248: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1082]   Size: 540.06MiB | Requested Size: 61.32MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.55GiB | Requested Size: 2.55GiB | in_use: 1 | bin_num: -1\n",
      "2024-12-06 06:17:59.728253: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1089] Next region of size 12100173824\n",
      "2024-12-06 06:17:59.728262: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000000 of size 256 next 1\n",
      "2024-12-06 06:17:59.728267: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000100 of size 1280 next 2\n",
      "2024-12-06 06:17:59.728271: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000600 of size 256 next 3\n",
      "2024-12-06 06:17:59.728276: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000700 of size 256 next 4\n",
      "2024-12-06 06:17:59.728280: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000800 of size 256 next 5\n",
      "2024-12-06 06:17:59.728285: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000900 of size 256 next 6\n",
      "2024-12-06 06:17:59.728289: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000a00 of size 256 next 9\n",
      "2024-12-06 06:17:59.728310: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000b00 of size 256 next 10\n",
      "2024-12-06 06:17:59.728314: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000c00 of size 256 next 11\n",
      "2024-12-06 06:17:59.728319: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000d00 of size 256 next 14\n",
      "2024-12-06 06:17:59.728323: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000e00 of size 256 next 16\n",
      "2024-12-06 06:17:59.728328: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2000f00 of size 256 next 18\n",
      "2024-12-06 06:17:59.728332: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001000 of size 256 next 20\n",
      "2024-12-06 06:17:59.728337: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001100 of size 256 next 22\n",
      "2024-12-06 06:17:59.728342: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001200 of size 256 next 24\n",
      "2024-12-06 06:17:59.728363: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001300 of size 256 next 26\n",
      "2024-12-06 06:17:59.728367: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001400 of size 256 next 28\n",
      "2024-12-06 06:17:59.728372: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001500 of size 256 next 30\n",
      "2024-12-06 06:17:59.728377: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001600 of size 256 next 32\n",
      "2024-12-06 06:17:59.728381: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001700 of size 256 next 34\n",
      "2024-12-06 06:17:59.728386: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001800 of size 256 next 36\n",
      "2024-12-06 06:17:59.728391: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001900 of size 256 next 38\n",
      "2024-12-06 06:17:59.728396: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001a00 of size 256 next 40\n",
      "2024-12-06 06:17:59.728402: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001b00 of size 256 next 42\n",
      "2024-12-06 06:17:59.728407: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001c00 of size 256 next 44\n",
      "2024-12-06 06:17:59.728412: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001d00 of size 256 next 46\n",
      "2024-12-06 06:17:59.728416: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001e00 of size 256 next 48\n",
      "2024-12-06 06:17:59.728421: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2001f00 of size 256 next 50\n",
      "2024-12-06 06:17:59.728426: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002000 of size 256 next 52\n",
      "2024-12-06 06:17:59.728430: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002100 of size 256 next 54\n",
      "2024-12-06 06:17:59.728435: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002200 of size 256 next 56\n",
      "2024-12-06 06:17:59.728440: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002300 of size 256 next 58\n",
      "2024-12-06 06:17:59.728445: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002400 of size 256 next 60\n",
      "2024-12-06 06:17:59.728449: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002500 of size 256 next 62\n",
      "2024-12-06 06:17:59.728454: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002600 of size 256 next 64\n",
      "2024-12-06 06:17:59.728459: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002700 of size 256 next 66\n",
      "2024-12-06 06:17:59.728463: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002800 of size 256 next 68\n",
      "2024-12-06 06:17:59.728468: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002900 of size 256 next 70\n",
      "2024-12-06 06:17:59.728473: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002a00 of size 256 next 72\n",
      "2024-12-06 06:17:59.728477: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002b00 of size 256 next 74\n",
      "2024-12-06 06:17:59.728482: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002c00 of size 256 next 76\n",
      "2024-12-06 06:17:59.728487: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002d00 of size 256 next 78\n",
      "2024-12-06 06:17:59.728491: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002e00 of size 256 next 79\n",
      "2024-12-06 06:17:59.728497: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2002f00 of size 1024 next 80\n",
      "2024-12-06 06:17:59.728502: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2003300 of size 256 next 86\n",
      "2024-12-06 06:17:59.728506: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2003400 of size 1024 next 85\n",
      "2024-12-06 06:17:59.728511: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2003800 of size 256 next 88\n",
      "2024-12-06 06:17:59.728516: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2003900 of size 256 next 89\n",
      "2024-12-06 06:17:59.728520: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2003a00 of size 256 next 93\n",
      "2024-12-06 06:17:59.728525: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2003b00 of size 256 next 95\n",
      "2024-12-06 06:17:59.728530: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2003c00 of size 256 next 97\n",
      "2024-12-06 06:17:59.728534: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2003d00 of size 256 next 99\n",
      "2024-12-06 06:17:59.728539: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2003e00 of size 256 next 7\n",
      "2024-12-06 06:17:59.728544: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2003f00 of size 6912 next 8\n",
      "2024-12-06 06:17:59.728551: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2005a00 of size 256 next 102\n",
      "2024-12-06 06:17:59.728556: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2005b00 of size 256 next 103\n",
      "2024-12-06 06:17:59.728560: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2005c00 of size 256 next 105\n",
      "2024-12-06 06:17:59.728565: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2005d00 of size 256 next 107\n",
      "2024-12-06 06:17:59.728570: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2005e00 of size 256 next 109\n",
      "2024-12-06 06:17:59.728574: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2005f00 of size 256 next 111\n",
      "2024-12-06 06:17:59.728579: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006000 of size 256 next 113\n",
      "2024-12-06 06:17:59.728584: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006100 of size 256 next 115\n",
      "2024-12-06 06:17:59.728588: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006200 of size 256 next 117\n",
      "2024-12-06 06:17:59.728593: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006300 of size 256 next 119\n",
      "2024-12-06 06:17:59.728598: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006400 of size 256 next 121\n",
      "2024-12-06 06:17:59.728602: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006500 of size 256 next 123\n",
      "2024-12-06 06:17:59.728607: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006600 of size 256 next 125\n",
      "2024-12-06 06:17:59.728612: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006700 of size 256 next 127\n",
      "2024-12-06 06:17:59.728616: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006800 of size 256 next 129\n",
      "2024-12-06 06:17:59.728621: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006900 of size 256 next 131\n",
      "2024-12-06 06:17:59.728626: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006a00 of size 256 next 133\n",
      "2024-12-06 06:17:59.728630: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006b00 of size 256 next 135\n",
      "2024-12-06 06:17:59.728635: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006c00 of size 256 next 137\n",
      "2024-12-06 06:17:59.728640: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006d00 of size 256 next 139\n",
      "2024-12-06 06:17:59.728644: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006e00 of size 256 next 141\n",
      "2024-12-06 06:17:59.728649: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2006f00 of size 256 next 143\n",
      "2024-12-06 06:17:59.728654: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007000 of size 256 next 145\n",
      "2024-12-06 06:17:59.728659: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007100 of size 256 next 147\n",
      "2024-12-06 06:17:59.728663: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007200 of size 256 next 149\n",
      "2024-12-06 06:17:59.728668: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007300 of size 256 next 151\n",
      "2024-12-06 06:17:59.728673: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007400 of size 256 next 153\n",
      "2024-12-06 06:17:59.728677: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007500 of size 1280 next 156\n",
      "2024-12-06 06:17:59.728682: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007a00 of size 256 next 155\n",
      "2024-12-06 06:17:59.728687: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007b00 of size 256 next 90\n",
      "2024-12-06 06:17:59.728693: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007c00 of size 256 next 171\n",
      "2024-12-06 06:17:59.728698: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007d00 of size 256 next 174\n",
      "2024-12-06 06:17:59.728703: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f9ec2007e00 of size 256 next 161\n",
      "2024-12-06 06:17:59.728707: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2007f00 of size 256 next 165\n",
      "2024-12-06 06:17:59.728712: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2008000 of size 1024 next 167\n",
      "2024-12-06 06:17:59.728717: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2008400 of size 284160 next 13\n",
      "2024-12-06 06:17:59.728723: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec204da00 of size 147456 next 12\n",
      "2024-12-06 06:17:59.728728: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2071a00 of size 147456 next 15\n",
      "2024-12-06 06:17:59.728733: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2095a00 of size 147456 next 17\n",
      "2024-12-06 06:17:59.728739: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec20b9a00 of size 147456 next 19\n",
      "2024-12-06 06:17:59.728744: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec20dda00 of size 147456 next 21\n",
      "2024-12-06 06:17:59.728749: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2101a00 of size 147456 next 23\n",
      "2024-12-06 06:17:59.728754: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2125a00 of size 147456 next 25\n",
      "2024-12-06 06:17:59.728758: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2149a00 of size 147456 next 27\n",
      "2024-12-06 06:17:59.728763: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec216da00 of size 147456 next 29\n",
      "2024-12-06 06:17:59.728768: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2191a00 of size 147456 next 31\n",
      "2024-12-06 06:17:59.728772: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec21b5a00 of size 147456 next 33\n",
      "2024-12-06 06:17:59.728777: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec21d9a00 of size 147456 next 35\n",
      "2024-12-06 06:17:59.728782: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec21fda00 of size 147456 next 37\n",
      "2024-12-06 06:17:59.728787: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2221a00 of size 147456 next 39\n",
      "2024-12-06 06:17:59.728791: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2245a00 of size 147456 next 41\n",
      "2024-12-06 06:17:59.728796: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2269a00 of size 147456 next 43\n",
      "2024-12-06 06:17:59.728801: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec228da00 of size 147456 next 45\n",
      "2024-12-06 06:17:59.728805: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec22b1a00 of size 147456 next 47\n",
      "2024-12-06 06:17:59.728810: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec22d5a00 of size 147456 next 49\n",
      "2024-12-06 06:17:59.728815: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec22f9a00 of size 147456 next 51\n",
      "2024-12-06 06:17:59.728820: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec231da00 of size 147456 next 53\n",
      "2024-12-06 06:17:59.728824: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2341a00 of size 147456 next 55\n",
      "2024-12-06 06:17:59.728829: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2365a00 of size 147456 next 57\n",
      "2024-12-06 06:17:59.728834: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2389a00 of size 147456 next 59\n",
      "2024-12-06 06:17:59.728840: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec23ada00 of size 147456 next 61\n",
      "2024-12-06 06:17:59.728845: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec23d1a00 of size 147456 next 63\n",
      "2024-12-06 06:17:59.728850: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec23f5a00 of size 147456 next 65\n",
      "2024-12-06 06:17:59.728854: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2419a00 of size 147456 next 67\n",
      "2024-12-06 06:17:59.728859: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec243da00 of size 147456 next 69\n",
      "2024-12-06 06:17:59.728864: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2461a00 of size 147456 next 71\n",
      "2024-12-06 06:17:59.728868: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2485a00 of size 147456 next 73\n",
      "2024-12-06 06:17:59.728873: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec24a9a00 of size 147456 next 75\n",
      "2024-12-06 06:17:59.728878: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec24cda00 of size 147456 next 77\n",
      "2024-12-06 06:17:59.728883: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec24f1a00 of size 6912 next 164\n",
      "2024-12-06 06:17:59.728887: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec24f3500 of size 6912 next 163\n",
      "2024-12-06 06:17:59.728892: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f9ec24f5000 of size 6912 next 162\n",
      "2024-12-06 06:17:59.728897: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec24f6b00 of size 274176 next 91\n",
      "2024-12-06 06:17:59.728903: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2539a00 of size 147456 next 94\n",
      "2024-12-06 06:17:59.728907: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec255da00 of size 147456 next 96\n",
      "2024-12-06 06:17:59.728912: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2581a00 of size 147456 next 98\n",
      "2024-12-06 06:17:59.728917: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec25a5a00 of size 147456 next 100\n",
      "2024-12-06 06:17:59.728922: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec25c9a00 of size 147456 next 101\n",
      "2024-12-06 06:17:59.728926: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec25eda00 of size 147456 next 82\n",
      "2024-12-06 06:17:59.728931: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2611a00 of size 589824 next 81\n",
      "2024-12-06 06:17:59.728937: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec26a1a00 of size 147456 next 110\n",
      "2024-12-06 06:17:59.728941: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec26c5a00 of size 147456 next 112\n",
      "2024-12-06 06:17:59.728946: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec26e9a00 of size 147456 next 114\n",
      "2024-12-06 06:17:59.728951: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec270da00 of size 147456 next 116\n",
      "2024-12-06 06:17:59.728956: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2731a00 of size 147456 next 118\n",
      "2024-12-06 06:17:59.728961: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2755a00 of size 147456 next 120\n",
      "2024-12-06 06:17:59.728966: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2779a00 of size 147456 next 122\n",
      "2024-12-06 06:17:59.728971: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec279da00 of size 147456 next 124\n",
      "2024-12-06 06:17:59.728976: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec27c1a00 of size 147456 next 126\n",
      "2024-12-06 06:17:59.728980: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec27e5a00 of size 147456 next 128\n",
      "2024-12-06 06:17:59.728985: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2809a00 of size 147456 next 130\n",
      "2024-12-06 06:17:59.728990: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec282da00 of size 147456 next 132\n",
      "2024-12-06 06:17:59.728995: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2851a00 of size 147456 next 134\n",
      "2024-12-06 06:17:59.728999: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2875a00 of size 147456 next 136\n",
      "2024-12-06 06:17:59.729004: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2899a00 of size 147456 next 138\n",
      "2024-12-06 06:17:59.729009: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec28bda00 of size 147456 next 140\n",
      "2024-12-06 06:17:59.729014: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec28e1a00 of size 147456 next 142\n",
      "2024-12-06 06:17:59.729018: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2905a00 of size 147456 next 144\n",
      "2024-12-06 06:17:59.729023: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2929a00 of size 147456 next 146\n",
      "2024-12-06 06:17:59.729028: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec294da00 of size 147456 next 148\n",
      "2024-12-06 06:17:59.729033: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2971a00 of size 147456 next 150\n",
      "2024-12-06 06:17:59.729037: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2995a00 of size 589824 next 152\n",
      "2024-12-06 06:17:59.729042: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2a25a00 of size 6912 next 160\n",
      "2024-12-06 06:17:59.729047: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f9ec2a27500 of size 730368 next 154\n",
      "2024-12-06 06:17:59.729052: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2ad9a00 of size 589824 next 166\n",
      "2024-12-06 06:17:59.729056: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2b69a00 of size 147456 next 84\n",
      "2024-12-06 06:17:59.729061: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2b8da00 of size 147456 next 104\n",
      "2024-12-06 06:17:59.729066: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2bb1a00 of size 147456 next 106\n",
      "2024-12-06 06:17:59.729071: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2bd5a00 of size 147456 next 158\n",
      "2024-12-06 06:17:59.729075: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2bf9a00 of size 589824 next 157\n",
      "2024-12-06 06:17:59.729080: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec2c89a00 of size 32151040 next 159\n",
      "2024-12-06 06:17:59.729086: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ec4b33000 of size 128603648 next 108\n",
      "2024-12-06 06:17:59.729091: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9ecc5d8600 of size 2743541760 next 92\n",
      "2024-12-06 06:17:59.729097: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9f6fe4a600 of size 128603648 next 172\n",
      "2024-12-06 06:17:59.729101: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7f9f778efc00 of size 128603648 next 87\n",
      "2024-12-06 06:17:59.729106: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7f9f7f395200 of size 2743541760 next 168\n",
      "2024-12-06 06:17:59.729111: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7fa022c07200 of size 2872145408 next 83\n",
      "2024-12-06 06:17:59.729116: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] InUse at 7fa0cdf1e800 of size 2743541760 next 169\n",
      "2024-12-06 06:17:59.729121: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1109] Free  at 7fa171790800 of size 566294528 next 18446744073709551615\n",
      "2024-12-06 06:17:59.729127: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114]      Summary of in-use Chunks by size: \n",
      "2024-12-06 06:17:59.729151: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 82 Chunks of size 256 totalling 20.5KiB\n",
      "2024-12-06 06:17:59.729158: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 3 Chunks of size 1024 totalling 3.0KiB\n",
      "2024-12-06 06:17:59.729163: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2024-12-06 06:17:59.729169: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 4 Chunks of size 6912 totalling 27.0KiB\n",
      "2024-12-06 06:17:59.729174: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 64 Chunks of size 147456 totalling 9.00MiB\n",
      "2024-12-06 06:17:59.729180: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 274176 totalling 267.8KiB\n",
      "2024-12-06 06:17:59.729186: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 284160 totalling 277.5KiB\n",
      "2024-12-06 06:17:59.729191: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 4 Chunks of size 589824 totalling 2.25MiB\n",
      "2024-12-06 06:17:59.729197: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 32151040 totalling 30.66MiB\n",
      "2024-12-06 06:17:59.729204: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 2 Chunks of size 128603648 totalling 245.29MiB\n",
      "2024-12-06 06:17:59.729209: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 3 Chunks of size 2743541760 totalling 7.67GiB\n",
      "2024-12-06 06:17:59.729214: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] 1 Chunks of size 2872145408 totalling 2.67GiB\n",
      "2024-12-06 06:17:59.729220: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1121] Sum Total of in-use chunks: 10.62GiB\n",
      "2024-12-06 06:17:59.729226: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1123] Total bytes in pool: 12100173824 memory_limit_: 12100173824 available bytes: 0 curr_region_allocation_bytes_: 24200347648\n",
      "2024-12-06 06:17:59.729236: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1128] Stats: \n",
      "Limit:                     12100173824\n",
      "InUse:                     11404538112\n",
      "MaxInUse:                  11597450496\n",
      "NumAllocs:                         961\n",
      "MaxAllocSize:               2872145408\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-12-06 06:17:59.729250: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:508] ************************************************************************************************____\n",
      "2024-12-06 06:17:59.729275: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at conv_ops_impl.h:973 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[1,64,3228,3320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2024-12-06 06:17:59.729300: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[1,64,3228,3320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1,64,3228,3320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_GPU_ALLOCATOR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda_malloc_async\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## 여기\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mresolve_and_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdemo/0001.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mresolve_and_plot\u001b[0;34m(lr_image_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve_and_plot\u001b[39m(lr_image_path):\n\u001b[1;32m      6\u001b[0m     lr \u001b[38;5;241m=\u001b[39m load_image(lr_image_path)\n\u001b[0;32m----> 7\u001b[0m     sr \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     plot_sample(lr, sr)\n",
      "File \u001b[0;32m~/mml/ml/00 SR/model/common.py:9\u001b[0m, in \u001b[0;36mresolve_single\u001b[0;34m(model, lr)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve_single\u001b[39m(model, lr):\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/mml/ml/00 SR/model/common.py:14\u001b[0m, in \u001b[0;36mresolve\u001b[0;34m(model, lr_batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve\u001b[39m(model, lr_batch):\n\u001b[1;32m     13\u001b[0m     lr_batch \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(lr_batch, tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 14\u001b[0m     sr_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     sr_batch \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mclip_by_value(sr_batch, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m     16\u001b[0m     sr_batch \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mround(sr_batch)\n",
      "File \u001b[0;32m~/anaconda3/envs/mml/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1043\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m-> 1043\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1046\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/mml/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:420\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    403\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m  In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mml/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:556\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    553\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 556\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mflat_output_ids, nest\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/anaconda3/envs/mml/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1043\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m-> 1043\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1046\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/mml/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py:254\u001b[0m, in \u001b[0;36mConv.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_causal:  \u001b[38;5;66;03m# Apply causal padding to inputs for Conv1D.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mpad(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_causal_padding(inputs))\n\u001b[0;32m--> 254\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convolution_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m    257\u001b[0m   output_rank \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "File \u001b[0;32m~/anaconda3/envs/mml/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/mml/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1,64,3228,3320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "## 여기\n",
    "resolve_and_plot('demo/0001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_and_plot2('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import signal\n",
    "\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
