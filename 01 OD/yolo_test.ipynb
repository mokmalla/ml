{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/san/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics.data.utils import autosplit\n",
    "from ultralytics.utils.ops import xyxy2xywhn\n",
    "from ultralytics.utils import downloads\n",
    "from ultralytics.utils import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(fname=Path('xView/xView_train.geojson')):\n",
    "    # Convert xView geoJSON labels to YOLO format\n",
    "    path = fname.parent\n",
    "    with open(fname) as f:\n",
    "        print(f'Loading {fname}...')\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Make dirs\n",
    "    labels = Path(path / 'labels' / 'train')\n",
    "    os.system(f'rm -rf {labels}')\n",
    "    labels.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # xView classes 11-94 to 0-59\n",
    "    xview_class2index = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, 2, -1, 3, -1, 4, 5, 6, 7, 8, -1, 9, 10, 11,\n",
    "                        12, 13, 14, 15, -1, -1, 16, 17, 18, 19, 20, 21, 22, -1, 23, 24, 25, -1, 26, 27, -1, 28, -1,\n",
    "                        29, 30, 31, 32, 33, 34, 35, 36, 37, -1, 38, 39, 40, 41, 42, 43, 44, 45, -1, -1, -1, -1, 46,\n",
    "                        47, 48, 49, -1, 50, 51, -1, 52, -1, -1, -1, 53, 54, -1, 55, -1, -1, 56, -1, 57, -1, 58, 59]\n",
    "\n",
    "    shapes = {}\n",
    "    for feature in tqdm(data['features'], desc=f'Converting {fname}'):\n",
    "        p = feature['properties']\n",
    "        if p['bounds_imcoords']:\n",
    "            id = p['image_id']\n",
    "            file = path / 'train_images' / id\n",
    "            if file.exists():  # 1395.tif missing\n",
    "                try:\n",
    "                    box = np.array([int(num) for num in p['bounds_imcoords'].split(\",\")])\n",
    "                    assert box.shape[0] == 4, f'incorrect box shape {box.shape[0]}'\n",
    "                    cls = p['type_id']\n",
    "                    cls = xview_class2index[int(cls)]  # xView class to 0-60\n",
    "                    assert 59 >= cls >= 0, f'incorrect class index {cls}'\n",
    "\n",
    "                    # Write YOLO label\n",
    "                    if id not in shapes:\n",
    "                        shapes[id] = Image.open(file).size\n",
    "                    box = xyxy2xywhn(box[None].astype(np.float), w=shapes[id][0], h=shapes[id][1], clip=True)\n",
    "                    with open((labels / id).with_suffix('.txt'), 'a') as f:\n",
    "                        f.write(f\"{cls} {' '.join(f'{x:.6f}' for x in box[0])}\\n\")  # write label.txt\n",
    "                except Exception as e:\n",
    "                    print(f'WARNING: skipping one label for {file}: {e}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download manually from https://challenge.xviewdataset.org\n",
    "# yaml_data = yaml.load('yolo.yaml')\n",
    "# dir = Path(yaml)  # dataset root dir\n",
    "# ../datasets/xViewd\n",
    "dir = Path('./datasets/xView')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.float = float  # np.floatÏùÑ floatÎ°ú Ïû¨Ï†ïÏùò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets/xView/xView_train.geojson...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:   4%|‚ñç         | 25452/601937 [00:01<00:40, 14278.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/2308.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2308.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:   5%|‚ñç         | 28379/601937 [00:02<00:39, 14453.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/2313.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:   5%|‚ñå         | 31267/601937 [00:02<00:39, 14323.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/2423.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:   7%|‚ñã         | 43465/601937 [00:03<00:37, 14720.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1457.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1468.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1468.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  10%|‚ñâ         | 59747/601937 [00:05<00:50, 10703.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/295.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/302.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  11%|‚ñà         | 66747/601937 [00:05<00:40, 13115.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/716.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/716.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/716.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  13%|‚ñà‚ñé        | 78832/601937 [00:06<00:34, 15098.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/886.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/888.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/888.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/888.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  19%|‚ñà‚ñä        | 112763/601937 [00:08<00:34, 14340.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/2544.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  20%|‚ñà‚ñà        | 123261/601937 [00:09<00:30, 15555.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1450.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1450.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1450.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1450.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1459.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  21%|‚ñà‚ñà‚ñè       | 128158/601937 [00:09<00:29, 15847.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1459.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  22%|‚ñà‚ñà‚ñè       | 131465/601937 [00:09<00:29, 16201.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1465.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1465.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1465.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1465.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  25%|‚ñà‚ñà‚ñå       | 151848/601937 [00:12<00:37, 11858.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/2031.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2031.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2031.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2031.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2031.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2031.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2031.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2031.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2031.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2031.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2032.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2032.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2032.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2032.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  27%|‚ñà‚ñà‚ñã       | 165212/601937 [00:13<00:31, 13806.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1052.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  30%|‚ñà‚ñà‚ñâ       | 178703/601937 [00:14<00:28, 14757.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/523.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/523.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  30%|‚ñà‚ñà‚ñà       | 181804/601937 [00:14<00:28, 14610.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/525.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  32%|‚ñà‚ñà‚ñà‚ñè      | 191261/601937 [00:14<00:27, 15066.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/548.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  35%|‚ñà‚ñà‚ñà‚ñç      | 210618/601937 [00:16<00:26, 14604.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1454.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1454.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  36%|‚ñà‚ñà‚ñà‚ñå      | 216421/601937 [00:16<00:31, 12143.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1585.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1585.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1586.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  36%|‚ñà‚ñà‚ñà‚ñã      | 219320/601937 [00:17<00:28, 13246.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1586.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  37%|‚ñà‚ñà‚ñà‚ñã      | 223529/601937 [00:17<00:27, 13609.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1606.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1606.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1606.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1607.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1607.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1607.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  38%|‚ñà‚ñà‚ñà‚ñä      | 228165/601937 [00:17<00:25, 14691.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1608.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  39%|‚ñà‚ñà‚ñà‚ñâ      | 235532/601937 [00:18<00:26, 14070.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/2591.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/2599.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 303568/601937 [00:23<00:22, 13541.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1121.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 368157/601937 [00:28<00:14, 15832.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1211.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 429161/601937 [00:32<00:11, 15522.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1422.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1422.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1422.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1422.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1422.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1422.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 434049/601937 [00:32<00:10, 15926.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1430.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1430.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 438747/601937 [00:33<00:10, 14896.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1436.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/1436.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 497462/601937 [00:37<00:07, 14233.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1178.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 501845/601937 [00:37<00:06, 14331.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/1184.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 589608/601937 [00:43<00:00, 14620.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/107.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/107.tif: incorrect class index -1\n",
      "WARNING: skipping one label for datasets/xView/train_images/109.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 594386/601937 [00:43<00:00, 15528.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping one label for datasets/xView/train_images/109.tif: incorrect class index -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting datasets/xView/xView_train.geojson: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 601937/601937 [00:44<00:00, 13487.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# urls = ['https://d307kc0mrhucc3.cloudfront.net/train_labels.zip',  # train labels\n",
    "#         'https://d307kc0mrhucc3.cloudfront.net/train_images.zip',  # 15G, 847 train images\n",
    "#         'https://d307kc0mrhucc3.cloudfront.net/val_images.zip']  # 5G, 282 val images (no labels)\n",
    "# downloads.download(urls, dir=dir)\n",
    "\n",
    "# Convert labels\n",
    "convert_labels(dir / 'xView_train.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Î∞òÎ≥µ Ïã§Ìñâ X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images\n",
    "images = Path(dir / 'images')\n",
    "images.mkdir(parents=True, exist_ok=True)\n",
    "Path(dir / 'train_images').rename(dir / 'images' / 'train')\n",
    "Path(dir / 'val_images').rename(dir / 'images' / 'val')\n",
    "\n",
    "# Split\n",
    "autosplit(dir / 'images' / 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.49 üöÄ Python-3.9.6 torch-2.5.1 CPU (Apple M2 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=./xView.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
      "Overriding model.yaml nc=80 with nc=60\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    442372  ultralytics.nn.modules.head.Detect           [60, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,601,540 parameters, 2,601,524 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/san/Library/Mobile Documents/com~apple~CloudDocs/01 KoreaUniv/24-2/s76(Capstone)/dev/ml/01 OD/datasets/xView/labels/train... 760 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 760/760 [00:06<00:00, 109.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/san/Library/Mobile Documents/com~apple~CloudDocs/01 KoreaUniv/24-2/s76(Capstone)/dev/ml/01 OD/datasets/xView/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/san/Library/Mobile Documents/com~apple~CloudDocs/01 KoreaUniv/24-2/s76(Capstone)/dev/ml/01 OD/datasets/xView/labels/train... 86 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86/86 [00:00<00:00, 112.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/san/Library/Mobile Documents/com~apple~CloudDocs/01 KoreaUniv/24-2/s76(Capstone)/dev/ml/01 OD/datasets/xView/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000156, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G       3.43      5.528      1.417       5405        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [18:13<00:00, 22.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [05:15<00:00, 105.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86      64690          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.394 hours.\n",
      "Optimizer stripped from runs/detect/train3/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from runs/detect/train3/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating runs/detect/train3/weights/best.pt...\n",
      "Ultralytics 8.3.49 üöÄ Python-3.9.6 torch-2.5.1 CPU (Apple M2 Pro)\n",
      "YOLO11n summary (fused): 238 layers, 2,593,852 parameters, 0 gradients, 6.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:24<00:00,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86      64690          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.9ms preprocess, 165.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Test training with minimal epochs\n",
    "results = model.train(data=\"./xView.yaml\", epochs=1, imgsz=640, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
